{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZbLBuKoARJfswnvtP6n4W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Downloading data using gdown\n","!gdown 1HwXjx-eubi_aQJoZXBTEw527sgrOO1Gx # train_csv\n","!gdown 18SeMBB0xEcnx81JdA5fMlk82U40Z8TyP # train_labels\n","!gdown 1QX8G7PnK6F5teCSmUN-9Vm8TFhkVCOyW # test_csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDgBbvwAAzpl","executionInfo":{"status":"ok","timestamp":1670593787656,"user_tz":-330,"elapsed":8767,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"b5269aa6-75f5-4a0b-d0c6-10325d8dbbcb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1HwXjx-eubi_aQJoZXBTEw527sgrOO1Gx\n","To: /content/train.csv.csv\n","100% 20.1M/20.1M [00:00<00:00, 61.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=18SeMBB0xEcnx81JdA5fMlk82U40Z8TyP\n","To: /content/train_labels.csv.csv\n","100% 1.15M/1.15M [00:00<00:00, 117MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1QX8G7PnK6F5teCSmUN-9Vm8TFhkVCOyW\n","To: /content/test.csv.csv\n","100% 5.02M/5.02M [00:00<00:00, 40.0MB/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"5lB01B3LSH7v"},"source":["# <font color='orange'>8. Data Pipeline for Model Deployment"]},{"cell_type":"markdown","metadata":{"id":"wXSZ6B2lTsjA"},"source":["A machine learning pipeline is used to help automate machine learning workflows. They operate by enabling a sequence of data to be transformed and correlated together in a model that can be tested and evaluated to achieve an outcome.\n","\n"," We will create two pipelines, one for prediction and one for model evaluation."]},{"cell_type":"markdown","metadata":{"id":"N3GMXddRQcV4"},"source":["##<font color='brown'>8.1 Installing/Importing Dependancies </font>"]},{"cell_type":"markdown","metadata":{"id":"kACr6S7VYwxn"},"source":["We have to install and/or import necessary library dependancies needed for our pipelines so that our pipelines run smoothly without any error."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"UuzpaT_6Ys_n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670593689269,"user_tz":-330,"elapsed":30337,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"78bfaf1a-5cc0-4c74-fbea-88de7ce62ba8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gdown==4.5.4\n","  Downloading gdown-4.5.4-py3-none-any.whl (14 kB)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown==4.5.4) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown==4.5.4) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown==4.5.4) (3.8.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown==4.5.4) (1.15.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown==4.5.4) (4.6.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==4.5.4) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==4.5.4) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==4.5.4) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==4.5.4) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==4.5.4) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.4.0\n","    Uninstalling gdown-4.4.0:\n","      Successfully uninstalled gdown-4.4.0\n","Successfully installed gdown-4.5.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting catboost\n","  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n","\u001b[K     |████████████████████████████████| 76.6 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.7.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n","Installing collected packages: catboost\n","Successfully installed catboost-1.1.1\n"]}],"source":["# Installing/Importing Dependancies\n","!pip install gdown==4.5.4\n","!pip install catboost\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import pandas as pd\n","import numpy as np\n","import random\n","import joblib\n","import gdown\n","from scipy.sparse import hstack\n","from catboost import CatBoostClassifier\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","source":["# Downloading data transformation and ml model files\n","!gdown 1ijMRu5HGAp0jOrrigFxzPM585LgKFso_ # transformations file\n","!gdown 1vZkZEBG4MiuQye1CI5SU7iys7DC6MwNY # ml model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y86Ss_1Z_YUo","executionInfo":{"status":"ok","timestamp":1670593691077,"user_tz":-330,"elapsed":1834,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"d599a68a-85ca-41e8-eb83-6021f876f588"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1ijMRu5HGAp0jOrrigFxzPM585LgKFso_\n","To: /content/data_transformations.rar\n","100% 13.3k/13.3k [00:00<00:00, 14.3MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1vZkZEBG4MiuQye1CI5SU7iys7DC6MwNY\n","To: /content/rf_model.rar\n","100% 32.8M/32.8M [00:00<00:00, 144MB/s]\n"]}]},{"cell_type":"code","source":["# Exracting compressed files\n","!unrar x \"data_transformations.rar\"\n","!unrar x \"rf_model.rar\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvWUrxO4_7uA","executionInfo":{"status":"ok","timestamp":1670593755370,"user_tz":-330,"elapsed":21709,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"fcb8802d-130c-4cfe-f7a5-1694f75187a3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n","\n","\n","Extracting from data_transformations.rar\n","\n","\n","Would you like to replace the existing file region_encoder\n","   919 bytes, modified on 2022-12-06 06:39\n","with a new one\n","   919 bytes, modified on 2022-12-06 06:39\n","\n","[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit y\n","\n","Extracting  region_encoder                                               \b\b\b\b  5%\b\b\b\b\b  OK \n","\n","Would you like to replace the existing file scheme_management_encoder\n","   832 bytes, modified on 2022-12-06 06:39\n","with a new one\n","   832 bytes, modified on 2022-12-06 06:39\n","\n","[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit a\n","\n","Extracting  scheme_management_encoder                                    \b\b\b\b 10%\b\b\b\b\b  OK \n","Extracting  source_class_encoder                                         \b\b\b\b 14%\b\b\b\b\b  OK \n","Extracting  source_type_encoder                                          \b\b\b\b 19%\b\b\b\b\b  OK \n","Extracting  water_quality_encoder                                        \b\b\b\b 23%\b\b\b\b\b  OK \n","Extracting  waterpoint_age_normalizer                                    \b\b\b\b 27%\b\b\b\b\b  OK \n","Extracting  waterpoint_type_encoder                                      \b\b\b\b 32%\b\b\b\b\b  OK \n","Extracting  basin_encoder                                                \b\b\b\b 37%\b\b\b\b\b  OK \n","Extracting  extraction_type_class_encoder                                \b\b\b\b 41%\b\b\b\b\b  OK \n","Extracting  gps_height_normalizer                                        \b\b\b\b 45%\b\b\b\b\b  OK \n","Extracting  label_encoder                                                \b\b\b\b 48%\b\b\b\b\b  OK \n","Extracting  latitude_normalizer                                          \b\b\b\b 52%\b\b\b\b\b  OK \n","Extracting  lga_encoder                                                  \b\b\b\b 63%\b\b\b\b\b  OK \n","Extracting  longitude_normalizer                                         \b\b\b\b 67%\b\b\b\b\b  OK \n","Extracting  management_encoder                                           \b\b\b\b 72%\b\b\b\b\b  OK \n","Extracting  payment_type_encoder                                         \b\b\b\b 76%\b\b\b\b\b  OK \n","Extracting  permit_encoder                                               \b\b\b\b 80%\b\b\b\b\b  OK \n","Extracting  population_normalizer                                        \b\b\b\b 83%\b\b\b\b\b  OK \n","Extracting  public_meeting_encoder                                       \b\b\b\b 86%\b\b\b\b\b  OK \n","Extracting  quantity_encoder                                             \b\b\b\b 91%\b\b\b\b\b  OK \n","Extracting  record_month_encoder                                         \b\b\b\b 95%\b\b\b\b\b  OK \n","Extracting  record_year_encoder                                          \b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n","\n","UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n","\n","\n","Extracting from rf_model.rar\n","\n","Extracting  rf_model                                                     \b\b\b\b 12%\b\b\b\b 25%\b\b\b\b 38%\b\b\b\b 51%\b\b\b\b 63%\b\b\b\b 76%\b\b\b\b 89%\b\b\b\b 99%\b\b\b\b\b  OK \n","All OK\n"]}]},{"cell_type":"markdown","metadata":{"id":"bd1N7pMsTM4w"},"source":["##<font color='brown'>8.2 Prediction Pipeline Function </font>"]},{"cell_type":"markdown","metadata":{"id":"7djl6zeKZNRv"},"source":["We define predict pipeline function such that it takes input data to be predicted as input and returns the predictions as output."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"HGwj2FTFTWzl","executionInfo":{"status":"ok","timestamp":1670593765890,"user_tz":-330,"elapsed":4,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}}},"outputs":[],"source":["# prediction pipeline function\n","def predict(input_samples:any, return_id=True):\n","    \"\"\"\n","    This function takes the raw input samples and returns the predicted\n","    functionality status.\n","    \"\"\"\n","    # Columns names in data\n","    columns =  ['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n","                'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n","                'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n","                'ward', 'population', 'public_meeting', 'recorded_by',\n","                'scheme_management', 'scheme_name', 'permit', 'construction_year',\n","                'extraction_type', 'extraction_type_group', 'extraction_type_class',\n","                'management', 'management_group', 'payment', 'payment_type',\n","                'water_quality', 'quality_group', 'quantity', 'quantity_group',\n","                'source', 'source_type', 'source_class', 'waterpoint_type',\n","                'waterpoint_type_group']\n","    \n","    # Create dataframe from input samples\n","    input_df = pd.DataFrame(input_samples, columns=columns)\n","    \n","    # Imputing missing values\n","    ## gps_height\n","    GPS_HEIGHT_MEDIAN = 369.0\n","    input_df['gps_height'] = np.where(input_df['gps_height'] <= 0, GPS_HEIGHT_MEDIAN, input_df['gps_height'])\n","    ## latitude\n","    LATITUDE_MEDIAN = -5.0216\n","    input_df['latitude'] = np.where(input_df['latitude'] < -11.8, LATITUDE_MEDIAN, input_df['latitude'])\n","    input_df['latitude'] = np.where(input_df['latitude'] > -1, LATITUDE_MEDIAN, input_df['latitude'])\n","    ## longitude\n","    LONGITUDE_MEDIAN = 34.9087\n","    input_df['longitude'] = np.where(input_df['longitude'] < 29, LONGITUDE_MEDIAN, input_df['longitude'])\n","    input_df['longitude'] = np.where(input_df['longitude'] > 40.8, LONGITUDE_MEDIAN, input_df['longitude'])\n","    ## public_meeting\n","    PUBLIC_MEETING_MODE = True\n","    input_df['public_meeting'] = input_df['public_meeting'].fillna(PUBLIC_MEETING_MODE)\n","    ## scheme_management\n","    SCHEME_MANAGEMENT_MODE = \"VWC\"\n","    input_df['scheme_management'] = input_df['scheme_management'].fillna(SCHEME_MANAGEMENT_MODE)\n","    ## permit\n","    PERMIT_MODE = True\n","    input_df['permit'] = input_df['permit'].fillna(PERMIT_MODE)\n","    ## construction_year\n","    def year_imputer(x):\n","        \"\"\"\n","        Function to impute construction_year in data\n","        \"\"\"\n","        if x == 0:\n","            year_range = list(range(2000, 2013))\n","            impute_year = random.choice(year_range)\n","            return impute_year\n","\n","    input_df['construction_year'] = np.where(input_df['construction_year'] == 0,\n","                                           input_df['construction_year'].apply(year_imputer),\n","                                           input_df['construction_year'])\n","    \n","    # Feature Engineering\n","    ## Creating separate year and month columns\n","    input_df['date_recorded'] = pd.to_datetime(input_df['date_recorded'])\n","    input_df['record_year'] = input_df['date_recorded'].dt.year\n","    input_df['record_month'] = input_df['date_recorded'].dt.month\n","    input_df['waterpoint_age'] = input_df['record_year'] - input_df['construction_year']\n","\n","    # treating record_year and record_month as categorical features\n","    input_df[['record_year', 'record_month']] = input_df[['record_year', 'record_month']].astype('object')\n","\n","    # Feature Selection\n","    ids = input_df['id'].values\n","    dropped_features = ['id', 'amount_tsh', 'funder', 'installer', 'wpt_name',\n","                        'num_private', 'subvillage', 'region_code', 'district_code',\n","                        'ward', 'recorded_by', 'scheme_name', 'construction_year', \n","                        'extraction_type', 'extraction_type_group', 'management_group', \n","                        'payment', 'quality_group', 'quantity_group', 'source', \n","                        'waterpoint_type_group', 'date_recorded']\n","    input_df = input_df.drop(dropped_features, axis=1)\n","\n","    # Data Preparation\n","    \n","    ## gps_height\n","    gps_height_normalizer = joblib.load(\"gps_height_normalizer\")\n","    test_gps_height_normalized = gps_height_normalizer.transform(input_df['gps_height'].values.reshape(-1, 1))\n","    ## longitude\n","    longitude_normalizer = joblib.load(\"longitude_normalizer\")\n","    test_longitude_normalized = longitude_normalizer.transform(input_df['longitude'].values.reshape(-1, 1))\n","    ## latitude\n","    latitude_normalizer = joblib.load(\"latitude_normalizer\")\n","    test_latitude_normalized = latitude_normalizer.transform(input_df['latitude'].values.reshape(-1, 1))\n","    ## population\n","    population_normalizer = joblib.load(\"population_normalizer\")\n","    test_population_normalized = population_normalizer.transform(input_df['population'].values.reshape(-1, 1))\n","    ## waterpoint_age\n","    waterpoint_age_normalizer = joblib.load(\"waterpoint_age_normalizer\")\n","    test_waterpoint_age_normalized = waterpoint_age_normalizer.transform(input_df['waterpoint_age'].values.reshape(-1, 1))\n","    ## basin\n","    basin_encoder = joblib.load(\"basin_encoder\")\n","    test_basin_encoded = basin_encoder.transform(input_df['basin'].values.reshape(-1, 1))\n","    ## region\n","    region_encoder = joblib.load(\"region_encoder\")\n","    test_region_encoded = region_encoder.transform(input_df['region'].values.reshape(-1, 1))\n","    ## lga\n","    lga_encoder = joblib.load(\"lga_encoder\")  \n","    test_lga_encoded = lga_encoder.transform(input_df['lga'].values.reshape(-1, 1))\n","    ## public_meeting\n","    public_meeting_encoder = joblib.load(\"public_meeting_encoder\")\n","    test_public_meeting_encoded = public_meeting_encoder.transform(input_df['public_meeting'].values.reshape(-1, 1))\n","    ## scheme_management\n","    scheme_management_encoder = joblib.load(\"scheme_management_encoder\")\n","    test_scheme_management_encoded = scheme_management_encoder.transform(input_df['scheme_management'].values.reshape(-1, 1))\n","    ## permit\n","    permit_encoder = joblib.load(\"permit_encoder\")\n","    test_permit_encoded = permit_encoder.transform(input_df['permit'].values.reshape(-1, 1))\n","    ## extraction_type_class \n","    extraction_type_class_encoder = joblib.load(\"extraction_type_class_encoder\")\n","    test_extraction_type_class_encoded = extraction_type_class_encoder.transform(input_df['extraction_type_class'].values.reshape(-1, 1))\n","    ## management\n","    management_encoder = joblib.load(\"management_encoder\")\n","    test_management_encoded = management_encoder.transform(input_df['management'].values.reshape(-1, 1))\n","    ## payment_type\n","    payment_type_encoder = joblib.load(\"payment_type_encoder\")\n","    test_payment_type_encoded = payment_type_encoder.transform(input_df['payment_type'].values.reshape(-1, 1))\n","    ## water_quality\n","    water_quality_encoder = joblib.load(\"water_quality_encoder\")\n","    test_water_quality_encoded = water_quality_encoder.transform(input_df['water_quality'].values.reshape(-1, 1))\n","    ## quantity\n","    quantity_encoder = joblib.load(\"quantity_encoder\")\n","    test_quantity_encoded = quantity_encoder.transform(input_df['quantity'].values.reshape(-1, 1))\n","    ## source_type\n","    source_type_encoder = joblib.load(\"source_type_encoder\")\n","    test_source_type_encoded = source_type_encoder.transform(input_df['source_type'].values.reshape(-1, 1))\n","    ## source_class\n","    source_class_encoder = joblib.load(\"source_class_encoder\")\n","    test_source_class_encoded = source_class_encoder.transform(input_df['source_class'].values.reshape(-1, 1))\n","    ## waterpoint_type\n","    waterpoint_type_encoder = joblib.load(\"waterpoint_type_encoder\")\n","    test_waterpoint_type_encoded = waterpoint_type_encoder.transform(input_df['waterpoint_type'].values.reshape(-1, 1))\n","    ## record_year\n","    record_year_encoder = joblib.load(\"record_year_encoder\")\n","    test_record_year_encoded = record_year_encoder.transform(input_df['record_year'].values.reshape(-1, 1))\n","    ## record_month\n","    record_month_encoder = joblib.load(\"record_month_encoder\")\n","    test_record_month_encoded = record_month_encoder.transform(input_df['record_month'].values.reshape(-1, 1))\n","\n","    # Creating data matrix\n","    input_encoded = hstack([test_gps_height_normalized, test_longitude_normalized, test_latitude_normalized,\n","                        test_basin_encoded, test_region_encoded, test_lga_encoded, test_population_normalized,\n","                        test_public_meeting_encoded, test_scheme_management_encoded, test_permit_encoded,\n","                        test_extraction_type_class_encoded, test_management_encoded, test_payment_type_encoded,\n","                        test_water_quality_encoded, test_quantity_encoded, test_source_type_encoded,\n","                        test_source_class_encoded, test_waterpoint_type_encoded, test_record_year_encoded,\n","                        test_record_month_encoded, test_waterpoint_age_normalized]).tocsr()\n","\n","    # Load model\n","    model = joblib.load(\"rf_model\")\n","\n","    #predictions\n","    predictions = model.predict(input_encoded)\n","    label_encoder = joblib.load(\"label_encoder\")\n","    predictions = label_encoder.inverse_transform(predictions)\n","    if return_id:\n","        pred_dict = {\"id\":ids, \"status_group\":predictions}\n","    else:\n","        pred_dict = {\"status_group\":predictions}\n","    pred_df = pd.DataFrame(pred_dict)\n","    return pred_df"]},{"cell_type":"markdown","source":["__Getting Predictions using pipeline__:"],"metadata":{"id":"nhJUPi3kBBgk"}},{"cell_type":"code","source":["test_df = pd.read_csv(\"test.csv.csv\")\n","predictions = predict(test_df, return_id=False)\n","print(f\"input data for prediction shape: {test_df.shape}\")\n","print(f\"predictions shape               : {predictions.shape}\")\n","print(\"\\n\")\n","print(\"Predictions sample: \")\n","predictions.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"gnFElYFnBACx","executionInfo":{"status":"ok","timestamp":1670593790526,"user_tz":-330,"elapsed":2912,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"88cc761e-6f53-496f-ee8c-68a10523047c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["input data for prediction shape: (14850, 40)\n","predictions shape               : (14850, 1)\n","\n","\n","Predictions sample: \n"]},{"output_type":"execute_result","data":{"text/plain":["     status_group\n","0      functional\n","1      functional\n","2      functional\n","3  non functional\n","4      functional"],"text/html":["\n","  <div id=\"df-c4287b70-b42d-4257-b489-49f05258b366\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>status_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>functional</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>non functional</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>functional</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4287b70-b42d-4257-b489-49f05258b366')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c4287b70-b42d-4257-b489-49f05258b366 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c4287b70-b42d-4257-b489-49f05258b366');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Save Predictions\n","predictions.to_csv(\"predictions.csv\", index=False)"],"metadata":{"id":"AyweUJI4DEnm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XkF5YHJpTcAf"},"source":["##<font color='brown'>8.3 Evaluation Pipeline Function </font>"]},{"cell_type":"markdown","metadata":{"id":"1xb5BQY6Zc9Q"},"source":["We define evaluation pipeline function such that it takes input data and their corresponding labels as input and returns the metric value as output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRDj_uE9Tq5U"},"outputs":[],"source":["# evaluation pipeline function\n","def evaluate(input_samples:any, class_labels:any):\n","    \"\"\"\n","    This function takes the raw input samples and returns the predicted\n","    functionality status.\n","    \"\"\"\n","    # Columns names in data\n","    columns =  ['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n","                'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n","                'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n","                'ward', 'population', 'public_meeting', 'recorded_by',\n","                'scheme_management', 'scheme_name', 'permit', 'construction_year',\n","                'extraction_type', 'extraction_type_group', 'extraction_type_class',\n","                'management', 'management_group', 'payment', 'payment_type',\n","                'water_quality', 'quality_group', 'quantity', 'quantity_group',\n","                'source', 'source_type', 'source_class', 'waterpoint_type',\n","                'waterpoint_type_group']\n","    \n","    # Create dataframe from input samples\n","    input_df = pd.DataFrame(input_samples, columns=columns)\n","    \n","    # Imputing missing values\n","    ## gps_height\n","    GPS_HEIGHT_MEDIAN = 369.0\n","    input_df['gps_height'] = np.where(input_df['gps_height'] <= 0, GPS_HEIGHT_MEDIAN, input_df['gps_height'])\n","    ## latitude\n","    LATITUDE_MEDIAN = -5.0216\n","    input_df['latitude'] = np.where(input_df['latitude'] < -11.8, LATITUDE_MEDIAN, input_df['latitude'])\n","    input_df['latitude'] = np.where(input_df['latitude'] > -1, LATITUDE_MEDIAN, input_df['latitude'])\n","    ## longitude\n","    LONGITUDE_MEDIAN = 34.9087\n","    input_df['longitude'] = np.where(input_df['longitude'] < 29, LONGITUDE_MEDIAN, input_df['longitude'])\n","    input_df['longitude'] = np.where(input_df['longitude'] > 40.8, LONGITUDE_MEDIAN, input_df['longitude'])\n","    ## public_meeting\n","    PUBLIC_MEETING_MODE = True\n","    input_df['public_meeting'] = input_df['public_meeting'].fillna(PUBLIC_MEETING_MODE)\n","    ## scheme_management\n","    SCHEME_MANAGEMENT_MODE = \"VWC\"\n","    input_df['scheme_management'] = input_df['scheme_management'].fillna(SCHEME_MANAGEMENT_MODE)\n","    ## permit\n","    PERMIT_MODE = True\n","    input_df['permit'] = input_df['permit'].fillna(PERMIT_MODE)\n","    ## construction_year\n","    def year_imputer(x):\n","        \"\"\"\n","        Function to impute construction_year in data\n","        \"\"\"\n","        if x == 0:\n","            year_range = list(range(2000, 2013))\n","            impute_year = random.choice(year_range)\n","            return impute_year\n","\n","    input_df['construction_year'] = np.where(input_df['construction_year'] == 0,\n","                                           input_df['construction_year'].apply(year_imputer),\n","                                           input_df['construction_year'])\n","    \n","    # Feature Engineering\n","    ## Creating separate year and month columns\n","    input_df['date_recorded'] = pd.to_datetime(input_df['date_recorded'])\n","    input_df['record_year'] = input_df['date_recorded'].dt.year\n","    input_df['record_month'] = input_df['date_recorded'].dt.month\n","    input_df['waterpoint_age'] = input_df['record_year'] - input_df['construction_year']\n","\n","    # treating record_year and record_month as categorical features\n","    input_df[['record_year', 'record_month']] = input_df[['record_year', 'record_month']].astype('object')\n","    \n","    # Feature Selection\n","    ids = input_df['id'].values\n","    dropped_features = ['id', 'amount_tsh', 'funder', 'installer', 'wpt_name',\n","                        'num_private', 'subvillage', 'region_code', 'district_code',\n","                        'ward', 'recorded_by', 'scheme_name', 'construction_year', \n","                        'extraction_type', 'extraction_type_group', 'management_group', \n","                        'payment', 'quality_group', 'quantity_group', 'source', \n","                        'waterpoint_type_group', 'date_recorded']\n","    input_df = input_df.drop(dropped_features, axis=1)\n","\n","    # Data Preparation\n","    \n","    ## gps_height\n","    gps_height_normalizer = joblib.load(\"gps_height_normalizer\")\n","    test_gps_height_normalized = gps_height_normalizer.transform(input_df['gps_height'].values.reshape(-1, 1))\n","    ## longitude\n","    longitude_normalizer = joblib.load(\"longitude_normalizer\")\n","    test_longitude_normalized = longitude_normalizer.transform(input_df['longitude'].values.reshape(-1, 1))\n","    ## latitude\n","    latitude_normalizer = joblib.load(\"latitude_normalizer\")\n","    test_latitude_normalized = latitude_normalizer.transform(input_df['latitude'].values.reshape(-1, 1))\n","    ## population\n","    population_normalizer = joblib.load(\"population_normalizer\")\n","    test_population_normalized = population_normalizer.transform(input_df['population'].values.reshape(-1, 1))\n","    ## waterpoint_age\n","    waterpoint_age_normalizer = joblib.load(\"waterpoint_age_normalizer\")\n","    test_waterpoint_age_normalized = waterpoint_age_normalizer.transform(input_df['waterpoint_age'].values.reshape(-1, 1))\n","    ## basin\n","    basin_encoder = joblib.load(\"basin_encoder\")\n","    test_basin_encoded = basin_encoder.transform(input_df['basin'].values.reshape(-1, 1))\n","    ## region\n","    region_encoder = joblib.load(\"region_encoder\")\n","    test_region_encoded = region_encoder.transform(input_df['region'].values.reshape(-1, 1))\n","    ## lga\n","    lga_encoder = joblib.load(\"lga_encoder\")  \n","    test_lga_encoded = lga_encoder.transform(input_df['lga'].values.reshape(-1, 1))\n","    ## public_meeting\n","    public_meeting_encoder = joblib.load(\"public_meeting_encoder\")\n","    test_public_meeting_encoded = public_meeting_encoder.transform(input_df['public_meeting'].values.reshape(-1, 1))\n","    ## scheme_management\n","    scheme_management_encoder = joblib.load(\"scheme_management_encoder\")\n","    test_scheme_management_encoded = scheme_management_encoder.transform(input_df['scheme_management'].values.reshape(-1, 1))\n","    ## permit\n","    permit_encoder = joblib.load(\"permit_encoder\")\n","    test_permit_encoded = permit_encoder.transform(input_df['permit'].values.reshape(-1, 1))\n","    ## extraction_type_class \n","    extraction_type_class_encoder = joblib.load(\"extraction_type_class_encoder\")\n","    test_extraction_type_class_encoded = extraction_type_class_encoder.transform(input_df['extraction_type_class'].values.reshape(-1, 1))\n","    ## management\n","    management_encoder = joblib.load(\"management_encoder\")\n","    test_management_encoded = management_encoder.transform(input_df['management'].values.reshape(-1, 1))\n","    ## payment_type\n","    payment_type_encoder = joblib.load(\"payment_type_encoder\")\n","    test_payment_type_encoded = payment_type_encoder.transform(input_df['payment_type'].values.reshape(-1, 1))\n","    ## water_quality\n","    water_quality_encoder = joblib.load(\"water_quality_encoder\")\n","    test_water_quality_encoded = water_quality_encoder.transform(input_df['water_quality'].values.reshape(-1, 1))\n","    ## quantity\n","    quantity_encoder = joblib.load(\"quantity_encoder\")\n","    test_quantity_encoded = quantity_encoder.transform(input_df['quantity'].values.reshape(-1, 1))\n","    ## source_type\n","    source_type_encoder = joblib.load(\"source_type_encoder\")\n","    test_source_type_encoded = source_type_encoder.transform(input_df['source_type'].values.reshape(-1, 1))\n","    ## source_class\n","    source_class_encoder = joblib.load(\"source_class_encoder\")\n","    test_source_class_encoded = source_class_encoder.transform(input_df['source_class'].values.reshape(-1, 1))\n","    ## waterpoint_type\n","    waterpoint_type_encoder = joblib.load(\"waterpoint_type_encoder\")\n","    test_waterpoint_type_encoded = waterpoint_type_encoder.transform(input_df['waterpoint_type'].values.reshape(-1, 1))\n","    ## record_year\n","    record_year_encoder = joblib.load(\"record_year_encoder\")\n","    test_record_year_encoded = record_year_encoder.transform(input_df['record_year'].values.reshape(-1, 1))\n","    ## record_month\n","    record_month_encoder = joblib.load(\"record_month_encoder\")\n","    test_record_month_encoded = record_month_encoder.transform(input_df['record_month'].values.reshape(-1, 1))\n","\n","    # Creating data matrix\n","    input_encoded = hstack([test_gps_height_normalized, test_longitude_normalized, test_latitude_normalized,\n","                        test_basin_encoded, test_region_encoded, test_lga_encoded, test_population_normalized,\n","                        test_public_meeting_encoded, test_scheme_management_encoded, test_permit_encoded,\n","                        test_extraction_type_class_encoded, test_management_encoded, test_payment_type_encoded,\n","                        test_water_quality_encoded, test_quantity_encoded, test_source_type_encoded,\n","                        test_source_class_encoded, test_waterpoint_type_encoded, test_record_year_encoded,\n","                        test_record_month_encoded, test_waterpoint_age_normalized]).tocsr()\n","\n","    # Load model\n","    model = joblib.load(\"mvc_model\")\n","\n","    #predictions\n","    predictions = model.predict(input_encoded)\n","    label_encoder = joblib.load(\"label_encoder\")\n","    predictions = label_encoder.inverse_transform(predictions)\n","    score = f1_score(class_labels, predictions, average='micro')\n","    score = np.round(score, 4)\n","    return score"]},{"cell_type":"code","source":["# Checking evaluation pipeline\n","input_data = pd.read_csv(\"train.csv.csv\")\n","labels = pd.read_csv(\"train_labels.csv.csv\")\n","labels = labels['status_group'].values\n","score = evaluate(input_data, labels)\n","print(f\"micro_f1_score for model: {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AW-81OOkFSAe","executionInfo":{"status":"ok","timestamp":1670324841308,"user_tz":-330,"elapsed":32479,"user":{"displayName":"Saket Ingale","userId":"07351841823515172879"}},"outputId":"f8dff8d8-e68c-4b9d-d811-239d8aac5566"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["micro_f1_score for model: 0.8848\n"]}]}]}